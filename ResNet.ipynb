{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNA1keCalJeRkRRlfZn/1+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushnaidu/MyProjects/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcV8m3HiilnM",
        "outputId": "357634a8-4225-45fc-e826-0e016ced9431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1/50\n",
            "352/352 - 32s - loss: 1.4648 - accuracy: 0.4700 - val_loss: 1.6474 - val_accuracy: 0.4404 - 32s/epoch - 91ms/step\n",
            "Epoch 2/50\n",
            "352/352 - 10s - loss: 1.0506 - accuracy: 0.6224 - val_loss: 1.5070 - val_accuracy: 0.5180 - 10s/epoch - 29ms/step\n",
            "Epoch 3/50\n",
            "352/352 - 10s - loss: 0.8582 - accuracy: 0.6949 - val_loss: 1.5414 - val_accuracy: 0.5584 - 10s/epoch - 29ms/step\n",
            "Epoch 4/50\n",
            "352/352 - 10s - loss: 0.7347 - accuracy: 0.7405 - val_loss: 0.9674 - val_accuracy: 0.6676 - 10s/epoch - 28ms/step\n",
            "Epoch 5/50\n",
            "352/352 - 10s - loss: 0.6331 - accuracy: 0.7788 - val_loss: 1.0121 - val_accuracy: 0.6584 - 10s/epoch - 29ms/step\n",
            "Epoch 6/50\n",
            "352/352 - 10s - loss: 0.5533 - accuracy: 0.8068 - val_loss: 1.0951 - val_accuracy: 0.6460 - 10s/epoch - 29ms/step\n",
            "Epoch 7/50\n",
            "352/352 - 10s - loss: 0.4899 - accuracy: 0.8283 - val_loss: 1.2836 - val_accuracy: 0.6270 - 10s/epoch - 30ms/step\n",
            "Epoch 8/50\n",
            "352/352 - 11s - loss: 0.4187 - accuracy: 0.8550 - val_loss: 1.3024 - val_accuracy: 0.6426 - 11s/epoch - 30ms/step\n",
            "Epoch 9/50\n",
            "352/352 - 11s - loss: 0.3623 - accuracy: 0.8752 - val_loss: 1.0876 - val_accuracy: 0.6882 - 11s/epoch - 30ms/step\n",
            "Epoch 10/50\n",
            "352/352 - 11s - loss: 0.3168 - accuracy: 0.8902 - val_loss: 1.4097 - val_accuracy: 0.6728 - 11s/epoch - 31ms/step\n",
            "Epoch 11/50\n",
            "352/352 - 11s - loss: 0.2655 - accuracy: 0.9077 - val_loss: 1.1689 - val_accuracy: 0.6802 - 11s/epoch - 30ms/step\n",
            "Epoch 12/50\n",
            "352/352 - 10s - loss: 0.2307 - accuracy: 0.9211 - val_loss: 1.1260 - val_accuracy: 0.7054 - 10s/epoch - 30ms/step\n",
            "Epoch 13/50\n",
            "352/352 - 10s - loss: 0.1902 - accuracy: 0.9340 - val_loss: 0.9411 - val_accuracy: 0.7394 - 10s/epoch - 30ms/step\n",
            "Epoch 14/50\n",
            "352/352 - 11s - loss: 0.1672 - accuracy: 0.9423 - val_loss: 1.2303 - val_accuracy: 0.7130 - 11s/epoch - 30ms/step\n",
            "Epoch 15/50\n",
            "352/352 - 11s - loss: 0.1495 - accuracy: 0.9492 - val_loss: 1.3948 - val_accuracy: 0.7118 - 11s/epoch - 30ms/step\n",
            "Epoch 16/50\n",
            "352/352 - 11s - loss: 0.1266 - accuracy: 0.9555 - val_loss: 1.9120 - val_accuracy: 0.6394 - 11s/epoch - 31ms/step\n",
            "Epoch 17/50\n",
            "352/352 - 11s - loss: 0.1171 - accuracy: 0.9593 - val_loss: 1.1356 - val_accuracy: 0.7422 - 11s/epoch - 30ms/step\n",
            "Epoch 18/50\n",
            "352/352 - 11s - loss: 0.1102 - accuracy: 0.9612 - val_loss: 1.3108 - val_accuracy: 0.7178 - 11s/epoch - 30ms/step\n",
            "Epoch 19/50\n",
            "352/352 - 11s - loss: 0.0986 - accuracy: 0.9657 - val_loss: 1.4274 - val_accuracy: 0.6934 - 11s/epoch - 31ms/step\n",
            "Epoch 20/50\n",
            "352/352 - 11s - loss: 0.0904 - accuracy: 0.9683 - val_loss: 1.2780 - val_accuracy: 0.7262 - 11s/epoch - 31ms/step\n",
            "Epoch 21/50\n",
            "352/352 - 11s - loss: 0.0855 - accuracy: 0.9702 - val_loss: 1.2883 - val_accuracy: 0.7290 - 11s/epoch - 31ms/step\n",
            "Epoch 22/50\n",
            "352/352 - 11s - loss: 0.0893 - accuracy: 0.9686 - val_loss: 1.8012 - val_accuracy: 0.6652 - 11s/epoch - 31ms/step\n",
            "Epoch 23/50\n",
            "352/352 - 11s - loss: 0.0772 - accuracy: 0.9730 - val_loss: 1.5224 - val_accuracy: 0.7130 - 11s/epoch - 30ms/step\n",
            "Epoch 24/50\n",
            "352/352 - 11s - loss: 0.0857 - accuracy: 0.9694 - val_loss: 1.4221 - val_accuracy: 0.7322 - 11s/epoch - 31ms/step\n",
            "Epoch 25/50\n",
            "352/352 - 11s - loss: 0.0809 - accuracy: 0.9708 - val_loss: 1.7790 - val_accuracy: 0.6998 - 11s/epoch - 30ms/step\n",
            "Epoch 26/50\n",
            "352/352 - 11s - loss: 0.0562 - accuracy: 0.9814 - val_loss: 1.4747 - val_accuracy: 0.7260 - 11s/epoch - 31ms/step\n",
            "Epoch 27/50\n",
            "352/352 - 11s - loss: 0.0700 - accuracy: 0.9760 - val_loss: 1.7610 - val_accuracy: 0.6858 - 11s/epoch - 31ms/step\n",
            "Epoch 28/50\n",
            "352/352 - 10s - loss: 0.0525 - accuracy: 0.9830 - val_loss: 1.6187 - val_accuracy: 0.7168 - 10s/epoch - 29ms/step\n",
            "Epoch 29/50\n",
            "352/352 - 11s - loss: 0.0616 - accuracy: 0.9777 - val_loss: 1.3890 - val_accuracy: 0.7364 - 11s/epoch - 31ms/step\n",
            "Epoch 30/50\n",
            "352/352 - 10s - loss: 0.0795 - accuracy: 0.9723 - val_loss: 1.4542 - val_accuracy: 0.7336 - 10s/epoch - 30ms/step\n",
            "Epoch 31/50\n",
            "352/352 - 11s - loss: 0.0553 - accuracy: 0.9807 - val_loss: 1.4169 - val_accuracy: 0.7192 - 11s/epoch - 31ms/step\n",
            "Epoch 32/50\n",
            "352/352 - 11s - loss: 0.0570 - accuracy: 0.9800 - val_loss: 1.2965 - val_accuracy: 0.7622 - 11s/epoch - 31ms/step\n",
            "Epoch 33/50\n",
            "352/352 - 11s - loss: 0.0534 - accuracy: 0.9814 - val_loss: 1.4540 - val_accuracy: 0.7456 - 11s/epoch - 31ms/step\n",
            "Epoch 34/50\n",
            "352/352 - 11s - loss: 0.0593 - accuracy: 0.9792 - val_loss: 1.5361 - val_accuracy: 0.7160 - 11s/epoch - 31ms/step\n",
            "Epoch 35/50\n",
            "352/352 - 11s - loss: 0.0497 - accuracy: 0.9828 - val_loss: 1.8203 - val_accuracy: 0.6916 - 11s/epoch - 31ms/step\n",
            "Epoch 36/50\n",
            "352/352 - 10s - loss: 0.0514 - accuracy: 0.9828 - val_loss: 1.3784 - val_accuracy: 0.7530 - 10s/epoch - 30ms/step\n",
            "Epoch 37/50\n",
            "352/352 - 11s - loss: 0.0556 - accuracy: 0.9800 - val_loss: 1.4750 - val_accuracy: 0.7314 - 11s/epoch - 31ms/step\n",
            "Epoch 38/50\n",
            "352/352 - 11s - loss: 0.0525 - accuracy: 0.9823 - val_loss: 1.3256 - val_accuracy: 0.7598 - 11s/epoch - 30ms/step\n",
            "Epoch 39/50\n",
            "352/352 - 11s - loss: 0.0436 - accuracy: 0.9852 - val_loss: 1.8353 - val_accuracy: 0.7218 - 11s/epoch - 31ms/step\n",
            "Epoch 40/50\n",
            "352/352 - 11s - loss: 0.0538 - accuracy: 0.9808 - val_loss: 1.6018 - val_accuracy: 0.7386 - 11s/epoch - 31ms/step\n",
            "Epoch 41/50\n",
            "352/352 - 11s - loss: 0.0426 - accuracy: 0.9850 - val_loss: 1.7335 - val_accuracy: 0.7324 - 11s/epoch - 30ms/step\n",
            "Epoch 42/50\n",
            "352/352 - 11s - loss: 0.0513 - accuracy: 0.9815 - val_loss: 1.8224 - val_accuracy: 0.7258 - 11s/epoch - 30ms/step\n",
            "Epoch 43/50\n",
            "352/352 - 10s - loss: 0.0494 - accuracy: 0.9832 - val_loss: 1.6714 - val_accuracy: 0.7198 - 10s/epoch - 29ms/step\n",
            "Epoch 44/50\n",
            "352/352 - 11s - loss: 0.0417 - accuracy: 0.9853 - val_loss: 1.4215 - val_accuracy: 0.7528 - 11s/epoch - 31ms/step\n",
            "Epoch 45/50\n",
            "352/352 - 11s - loss: 0.0427 - accuracy: 0.9846 - val_loss: 1.6314 - val_accuracy: 0.7408 - 11s/epoch - 30ms/step\n",
            "Epoch 46/50\n",
            "352/352 - 11s - loss: 0.0420 - accuracy: 0.9844 - val_loss: 1.4287 - val_accuracy: 0.7436 - 11s/epoch - 31ms/step\n",
            "Epoch 47/50\n",
            "352/352 - 11s - loss: 0.0418 - accuracy: 0.9850 - val_loss: 1.9264 - val_accuracy: 0.7180 - 11s/epoch - 30ms/step\n",
            "Epoch 48/50\n",
            "352/352 - 11s - loss: 0.0450 - accuracy: 0.9840 - val_loss: 1.8474 - val_accuracy: 0.7184 - 11s/epoch - 31ms/step\n",
            "Epoch 49/50\n",
            "352/352 - 11s - loss: 0.0413 - accuracy: 0.9851 - val_loss: 1.5970 - val_accuracy: 0.7424 - 11s/epoch - 30ms/step\n",
            "Epoch 50/50\n",
            "352/352 - 11s - loss: 0.0293 - accuracy: 0.9905 - val_loss: 1.8364 - val_accuracy: 0.7344 - 11s/epoch - 31ms/step\n",
            "Epoch 1/50\n",
            "352/352 - 34s - loss: 1.5286 - accuracy: 0.4611 - val_loss: 2.4412 - val_accuracy: 0.3706 - 34s/epoch - 98ms/step\n",
            "Epoch 2/50\n",
            "352/352 - 17s - loss: 1.0417 - accuracy: 0.6272 - val_loss: 1.1293 - val_accuracy: 0.6054 - 17s/epoch - 48ms/step\n",
            "Epoch 3/50\n",
            "352/352 - 17s - loss: 0.8465 - accuracy: 0.6995 - val_loss: 0.9787 - val_accuracy: 0.6628 - 17s/epoch - 48ms/step\n",
            "Epoch 4/50\n",
            "352/352 - 17s - loss: 0.7135 - accuracy: 0.7478 - val_loss: 0.9913 - val_accuracy: 0.6792 - 17s/epoch - 47ms/step\n",
            "Epoch 5/50\n",
            "352/352 - 17s - loss: 0.6078 - accuracy: 0.7893 - val_loss: 1.4224 - val_accuracy: 0.5672 - 17s/epoch - 47ms/step\n",
            "Epoch 6/50\n",
            "352/352 - 17s - loss: 0.5285 - accuracy: 0.8138 - val_loss: 1.0615 - val_accuracy: 0.6662 - 17s/epoch - 47ms/step\n",
            "Epoch 7/50\n",
            "352/352 - 17s - loss: 0.4526 - accuracy: 0.8431 - val_loss: 0.7936 - val_accuracy: 0.7382 - 17s/epoch - 47ms/step\n",
            "Epoch 8/50\n",
            "352/352 - 17s - loss: 0.3956 - accuracy: 0.8611 - val_loss: 0.8885 - val_accuracy: 0.7216 - 17s/epoch - 48ms/step\n",
            "Epoch 9/50\n",
            "352/352 - 17s - loss: 0.3332 - accuracy: 0.8831 - val_loss: 1.5665 - val_accuracy: 0.5974 - 17s/epoch - 47ms/step\n",
            "Epoch 10/50\n",
            "352/352 - 17s - loss: 0.2870 - accuracy: 0.8988 - val_loss: 1.0885 - val_accuracy: 0.6946 - 17s/epoch - 47ms/step\n",
            "Epoch 11/50\n",
            "352/352 - 16s - loss: 0.2387 - accuracy: 0.9163 - val_loss: 1.8398 - val_accuracy: 0.5874 - 16s/epoch - 47ms/step\n",
            "Epoch 12/50\n",
            "352/352 - 17s - loss: 0.1948 - accuracy: 0.9312 - val_loss: 1.0854 - val_accuracy: 0.7120 - 17s/epoch - 47ms/step\n",
            "Epoch 13/50\n",
            "352/352 - 17s - loss: 0.1722 - accuracy: 0.9398 - val_loss: 1.6889 - val_accuracy: 0.6518 - 17s/epoch - 48ms/step\n",
            "Epoch 14/50\n",
            "352/352 - 16s - loss: 0.1472 - accuracy: 0.9477 - val_loss: 1.6149 - val_accuracy: 0.6882 - 16s/epoch - 47ms/step\n",
            "Epoch 15/50\n",
            "352/352 - 17s - loss: 0.1257 - accuracy: 0.9563 - val_loss: 1.4142 - val_accuracy: 0.7150 - 17s/epoch - 47ms/step\n",
            "Epoch 16/50\n",
            "352/352 - 17s - loss: 0.1186 - accuracy: 0.9578 - val_loss: 1.2174 - val_accuracy: 0.7474 - 17s/epoch - 47ms/step\n",
            "Epoch 17/50\n",
            "352/352 - 17s - loss: 0.1049 - accuracy: 0.9641 - val_loss: 1.8262 - val_accuracy: 0.6694 - 17s/epoch - 48ms/step\n",
            "Epoch 18/50\n",
            "352/352 - 17s - loss: 0.0915 - accuracy: 0.9687 - val_loss: 1.6916 - val_accuracy: 0.6906 - 17s/epoch - 47ms/step\n",
            "Epoch 19/50\n",
            "352/352 - 17s - loss: 0.0960 - accuracy: 0.9657 - val_loss: 1.2459 - val_accuracy: 0.7308 - 17s/epoch - 47ms/step\n",
            "Epoch 20/50\n",
            "352/352 - 17s - loss: 0.0821 - accuracy: 0.9721 - val_loss: 1.9036 - val_accuracy: 0.6650 - 17s/epoch - 48ms/step\n",
            "Epoch 21/50\n",
            "352/352 - 17s - loss: 0.0773 - accuracy: 0.9728 - val_loss: 1.5955 - val_accuracy: 0.7118 - 17s/epoch - 48ms/step\n",
            "Epoch 22/50\n",
            "352/352 - 16s - loss: 0.0842 - accuracy: 0.9699 - val_loss: 1.2533 - val_accuracy: 0.7580 - 16s/epoch - 47ms/step\n",
            "Epoch 23/50\n",
            "352/352 - 17s - loss: 0.0559 - accuracy: 0.9808 - val_loss: 1.7045 - val_accuracy: 0.7012 - 17s/epoch - 47ms/step\n",
            "Epoch 24/50\n",
            "352/352 - 17s - loss: 0.0816 - accuracy: 0.9706 - val_loss: 1.6214 - val_accuracy: 0.7024 - 17s/epoch - 48ms/step\n",
            "Epoch 25/50\n",
            "352/352 - 17s - loss: 0.0757 - accuracy: 0.9738 - val_loss: 1.3871 - val_accuracy: 0.7236 - 17s/epoch - 48ms/step\n",
            "Epoch 26/50\n",
            "352/352 - 17s - loss: 0.0559 - accuracy: 0.9804 - val_loss: 1.6470 - val_accuracy: 0.7158 - 17s/epoch - 47ms/step\n",
            "Epoch 27/50\n",
            "352/352 - 17s - loss: 0.0617 - accuracy: 0.9784 - val_loss: 1.4739 - val_accuracy: 0.7324 - 17s/epoch - 47ms/step\n",
            "Epoch 28/50\n",
            "352/352 - 17s - loss: 0.0601 - accuracy: 0.9792 - val_loss: 2.5783 - val_accuracy: 0.6494 - 17s/epoch - 47ms/step\n",
            "Epoch 29/50\n",
            "352/352 - 17s - loss: 0.0572 - accuracy: 0.9797 - val_loss: 1.5142 - val_accuracy: 0.7236 - 17s/epoch - 48ms/step\n",
            "Epoch 30/50\n",
            "352/352 - 17s - loss: 0.0573 - accuracy: 0.9799 - val_loss: 1.3783 - val_accuracy: 0.7528 - 17s/epoch - 47ms/step\n",
            "Epoch 31/50\n",
            "352/352 - 17s - loss: 0.0553 - accuracy: 0.9808 - val_loss: 1.2377 - val_accuracy: 0.7630 - 17s/epoch - 47ms/step\n",
            "Epoch 32/50\n",
            "352/352 - 17s - loss: 0.0518 - accuracy: 0.9811 - val_loss: 1.4334 - val_accuracy: 0.7392 - 17s/epoch - 47ms/step\n",
            "Epoch 33/50\n",
            "352/352 - 17s - loss: 0.0580 - accuracy: 0.9798 - val_loss: 2.1271 - val_accuracy: 0.6818 - 17s/epoch - 47ms/step\n",
            "Epoch 34/50\n",
            "352/352 - 17s - loss: 0.0426 - accuracy: 0.9850 - val_loss: 1.5811 - val_accuracy: 0.7272 - 17s/epoch - 47ms/step\n",
            "Epoch 35/50\n",
            "352/352 - 17s - loss: 0.0484 - accuracy: 0.9830 - val_loss: 1.1874 - val_accuracy: 0.7820 - 17s/epoch - 47ms/step\n",
            "Epoch 36/50\n",
            "352/352 - 17s - loss: 0.0546 - accuracy: 0.9804 - val_loss: 1.4586 - val_accuracy: 0.7504 - 17s/epoch - 47ms/step\n",
            "Epoch 37/50\n",
            "352/352 - 17s - loss: 0.0366 - accuracy: 0.9871 - val_loss: 1.4600 - val_accuracy: 0.7520 - 17s/epoch - 48ms/step\n",
            "Epoch 38/50\n",
            "352/352 - 16s - loss: 0.0453 - accuracy: 0.9842 - val_loss: 1.9550 - val_accuracy: 0.7086 - 16s/epoch - 47ms/step\n",
            "Epoch 39/50\n",
            "352/352 - 17s - loss: 0.0473 - accuracy: 0.9833 - val_loss: 1.3040 - val_accuracy: 0.7710 - 17s/epoch - 47ms/step\n",
            "Epoch 40/50\n",
            "352/352 - 17s - loss: 0.0472 - accuracy: 0.9835 - val_loss: 1.9453 - val_accuracy: 0.6880 - 17s/epoch - 47ms/step\n",
            "Epoch 41/50\n",
            "352/352 - 17s - loss: 0.0350 - accuracy: 0.9881 - val_loss: 1.2959 - val_accuracy: 0.7672 - 17s/epoch - 48ms/step\n",
            "Epoch 42/50\n",
            "352/352 - 16s - loss: 0.0405 - accuracy: 0.9862 - val_loss: 1.7334 - val_accuracy: 0.7384 - 16s/epoch - 47ms/step\n",
            "Epoch 43/50\n",
            "352/352 - 17s - loss: 0.0525 - accuracy: 0.9816 - val_loss: 2.3742 - val_accuracy: 0.6628 - 17s/epoch - 48ms/step\n",
            "Epoch 44/50\n",
            "352/352 - 16s - loss: 0.0343 - accuracy: 0.9884 - val_loss: 1.3621 - val_accuracy: 0.7642 - 16s/epoch - 47ms/step\n",
            "Epoch 45/50\n",
            "352/352 - 17s - loss: 0.0318 - accuracy: 0.9893 - val_loss: 1.3451 - val_accuracy: 0.7656 - 17s/epoch - 48ms/step\n",
            "Epoch 46/50\n",
            "352/352 - 17s - loss: 0.0422 - accuracy: 0.9850 - val_loss: 1.4962 - val_accuracy: 0.7544 - 17s/epoch - 47ms/step\n",
            "Epoch 47/50\n",
            "352/352 - 16s - loss: 0.0372 - accuracy: 0.9863 - val_loss: 1.8990 - val_accuracy: 0.6988 - 16s/epoch - 47ms/step\n",
            "Epoch 48/50\n",
            "352/352 - 17s - loss: 0.0364 - accuracy: 0.9876 - val_loss: 1.5375 - val_accuracy: 0.7458 - 17s/epoch - 47ms/step\n",
            "Epoch 49/50\n",
            "352/352 - 17s - loss: 0.0324 - accuracy: 0.9887 - val_loss: 1.3528 - val_accuracy: 0.7704 - 17s/epoch - 48ms/step\n",
            "Epoch 50/50\n",
            "352/352 - 16s - loss: 0.0391 - accuracy: 0.9857 - val_loss: 2.0758 - val_accuracy: 0.7028 - 16s/epoch - 47ms/step\n",
            "ResNet20 - Test Loss: 1.9181, Test Accuracy: 0.7202\n",
            "ResNet32 - Test Loss: 2.1998, Test Accuracy: 0.6845\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
        "    conv = layers.Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer='he_normal')\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
        "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
        "\n",
        "            if stack > 0 and res_block == 0:\n",
        "                x = resnet_layer(inputs=x, num_filters=num_filters, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n",
        "            x = layers.add([x, y])\n",
        "            x = layers.Activation('relu')(x)\n",
        "\n",
        "        num_filters *= 2\n",
        "\n",
        "    x = layers.AveragePooling2D(pool_size=8)(x)\n",
        "    y = layers.Flatten()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(y)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define ResNet20 and ResNet32 models\n",
        "model_resnet20 = resnet_v1(input_shape=(32, 32, 3), depth=20)\n",
        "model_resnet32 = resnet_v1(input_shape=(32, 32, 3), depth=32)\n",
        "\n",
        "# Compile models\n",
        "model_resnet20.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_resnet32.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train ResNet20\n",
        "history_resnet20 = model_resnet20.fit(x_train, y_train, validation_split=0.1, epochs=50, batch_size=128, verbose=2)\n",
        "\n",
        "# Train ResNet32\n",
        "history_resnet32 = model_resnet32.fit(x_train, y_train, validation_split=0.1, epochs=50, batch_size=128, verbose=2)\n",
        "\n",
        "# Evaluate on test set\n",
        "loss_resnet20, accuracy_resnet20 = model_resnet20.evaluate(x_test, y_test, verbose=0)\n",
        "loss_resnet32, accuracy_resnet32 = model_resnet32.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"ResNet20 - Test Loss: {loss_resnet20:.4f}, Test Accuracy: {accuracy_resnet20:.4f}\")\n",
        "print(f\"ResNet32 - Test Loss: {loss_resnet32:.4f}, Test Accuracy: {accuracy_resnet32:.4f}\")\n"
      ]
    }
  ]
}